{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29eca14a",
   "metadata": {},
   "source": [
    "# Análise de Variância (ANOVA): Diferenciação Morfológica entre Espécies de Íris\n",
    "\n",
    "**Autor:** Jesse Fernandes\n",
    "**Data:** 2025-09-29  \n",
    "**Objetivo**: Implementar e interpretar uma análise ANOVA rigorosa com pós-testes  \n",
    "**Nível**: PhD/Pesquisa Avançada  \n",
    "**Dataset**: Íris de Fisher (1936)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c0b100",
   "metadata": {},
   "source": [
    "## 1. Fundamentação Teórica\n",
    "\n",
    "### 1.1 Análise de Variância (ANOVA)\n",
    "\n",
    "A análise de variância (ANOVA) é uma técnica estatística para avaliar diferenças entre médias de grupos em dados experimentais, desenvolvida por Sir Ronald Fisher. O teste realiza a comparação de médias através da análise da variância.\n",
    "\n",
    "A hipótese nula ($H_0$) testada na ANOVA é:\n",
    "$H_0: \\mu_1 = \\mu_2 = ... = \\mu_k$\n",
    "\n",
    "Contra a hipótese alternativa ($H_1$):\n",
    "$H_1:$ pelo menos uma média difere das demais\n",
    "\n",
    "A ANOVA decompõe a variância total dos dados em:\n",
    "- **Variância entre grupos** (SSB): variabilidade entre médias de grupos diferentes\n",
    "- **Variância dentro dos grupos** (SSW): variabilidade dentro de cada grupo\n",
    "\n",
    "A estatística de teste F é calculada como:\n",
    "\n",
    "$$F = \\frac{MSB}{MSW} = \\frac{SSB/(k-1)}{SSW/(N-k)}$$\n",
    "\n",
    "onde:\n",
    "- $k$ é o número de grupos\n",
    "- $N$ é o número total de observações\n",
    "- $MSB$ é a média quadrática entre grupos\n",
    "- $MSW$ é a média quadrática dentro dos grupos\n",
    "\n",
    "### 1.2 Suposições da ANOVA\n",
    "\n",
    "1. **Independência**: As observações devem ser independentes entre si\n",
    "2. **Normalidade**: Os dados em cada grupo devem seguir distribuição normal\n",
    "3. **Homocedasticidade**: A variância deve ser homogênea entre os grupos\n",
    "\n",
    "### 1.3 Testes Post-hoc\n",
    "\n",
    "Quando a ANOVA rejeita $H_0$, os testes post-hoc identificam quais grupos diferem entre si:\n",
    "\n",
    "- **Tukey HSD**: Controla a taxa de erro familiar, comparando todos os pares de médias\n",
    "- **Bonferroni**: Ajusta o nível de significância para múltiplas comparações\n",
    "- **Scheffé**: Mais conservador, adequado para comparações complexas de médias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4627b1",
   "metadata": {},
   "source": [
    "## 2. Configuração do Ambiente Científico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a39983",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mA execução de células com 'Python 3.13.7' requer o pacote ipykernel.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Crie um ambiente Python</a> com os pacotes necessários.\n",
      "\u001b[1;31mOu instale 'ipykernel' usando o comando: '\"c:/Program Files/Python313/python3.13t.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Configuração do ambiente científico\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuração do projeto\n",
    "project_root = Path(os.getcwd()).parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Imports científicos essenciais\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd, MultiComparison\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from sklearn import datasets\n",
    "import warnings\n",
    "\n",
    "# Configurações de reprodutibilidade\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurações de visualização profissional\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams.update({\n",
    "    'figure.figsize': (14, 8),\n",
    "    'font.size': 12,\n",
    "    'axes.labelsize': 14,\n",
    "    'axes.titlesize': 16,\n",
    "    'xtick.labelsize': 12,\n",
    "    'ytick.labelsize': 12,\n",
    "    'legend.fontsize': 12,\n",
    "    'figure.titlesize': 18,\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3\n",
    "})\n",
    "\n",
    "print(\"✅ Ambiente científico configurado\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"SciPy: {stats.__version__ if hasattr(stats, '__version__') else 'N/A'}\")\n",
    "print(f\"Statsmodels: {sm.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a49935",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Exploração do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc53e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    \"\"\"Classe para gerenciamento profissional de dados e análise exploratória.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_name=\"iris\"):\n",
    "        \"\"\"Inicializa o gerenciador de dados com um dataset específico.\"\"\"\n",
    "        self.dataset_name = dataset_name\n",
    "        self.data = None\n",
    "        self.feature_names = None\n",
    "        self.target_names = None\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Carrega o dataset e prepara para análise.\"\"\"\n",
    "        # Carregar dados\n",
    "        if self.dataset_name == \"iris\":\n",
    "            iris = datasets.load_iris()\n",
    "            self.feature_names = iris.feature_names\n",
    "            self.target_names = iris.target_names\n",
    "            \n",
    "            # Criar DataFrame\n",
    "            self.data = pd.DataFrame(data=iris.data, columns=self.feature_names)\n",
    "            self.data['species'] = [self.target_names[i] for i in iris.target]\n",
    "            \n",
    "            # Renomear colunas para formato mais adequado à análise estatística\n",
    "            self.data.columns = [\n",
    "                'sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species'\n",
    "            ]\n",
    "            \n",
    "            print(f\"✅ Dataset {self.dataset_name} carregado com sucesso\")\n",
    "            print(f\"Dimensões: {self.data.shape[0]} observações × {self.data.shape[1]} variáveis\")\n",
    "            print(f\"Espécies: {', '.join(self.data['species'].unique())}\")\n",
    "            print(f\"Variáveis: {', '.join(self.data.columns[:-1])}\")\n",
    "            \n",
    "            return self.data\n",
    "        else:\n",
    "            raise ValueError(f\"Dataset {self.dataset_name} não suportado\")\n",
    "    \n",
    "    def summarize_data(self):\n",
    "        \"\"\"Gera estatísticas descritivas do dataset.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Dataset não foi carregado. Execute load_data() primeiro.\")\n",
    "        \n",
    "        # Estatísticas descritivas gerais\n",
    "        print(\"\\nEstatísticas Descritivas Gerais:\")\n",
    "        display(self.data.describe().round(2))\n",
    "        \n",
    "        # Estatísticas por espécie\n",
    "        print(\"\\nEstatísticas por Espécie:\")\n",
    "        stats_by_species = self.data.groupby('species').describe().round(2)\n",
    "        display(stats_by_species)\n",
    "        \n",
    "        return stats_by_species\n",
    "    \n",
    "    def check_assumptions(self, var_name, alpha=0.05):\n",
    "        \"\"\"Verifica suposições estatísticas para ANOVA.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Dataset não foi carregado. Execute load_data() primeiro.\")\n",
    "        \n",
    "        species = self.data['species'].unique()\n",
    "        data_by_species = [self.data[self.data['species'] == sp][var_name] for sp in species]\n",
    "        \n",
    "        print(f\"\\n--- Verificação de Suposições para ANOVA: {var_name} ---\\n\")\n",
    "        \n",
    "        # 1. Teste de Normalidade (Shapiro-Wilk)\n",
    "        print(\"1. Teste de Normalidade (Shapiro-Wilk):\")\n",
    "        all_normal = True\n",
    "        for i, sp in enumerate(species):\n",
    "            stat, p = stats.shapiro(data_by_species[i])\n",
    "            normal = p > alpha\n",
    "            all_normal &= normal\n",
    "            print(f\"   • {sp}: W = {stat:.4f}, p = {p:.4f} {'✓' if normal else '✗'}\")\n",
    "        \n",
    "        # 2. Teste de Homogeneidade de Variâncias (Levene)\n",
    "        stat, p = stats.levene(*data_by_species)\n",
    "        homoscedasticity = p > alpha\n",
    "        print(f\"\\n2. Teste de Homogeneidade de Variâncias (Levene):\")\n",
    "        print(f\"   • W = {stat:.4f}, p = {p:.4f} {'✓' if homoscedasticity else '✗'}\")\n",
    "        \n",
    "        # Conclusão sobre suposições\n",
    "        print(\"\\nConclusão sobre suposições:\")\n",
    "        \n",
    "        if all_normal and homoscedasticity:\n",
    "            print(\"✅ Todas as suposições para ANOVA paramétrica foram atendidas.\")\n",
    "            recommendation = \"ANOVA paramétrica\"\n",
    "        elif homoscedasticity:\n",
    "            print(\"⚠️ Suposição de normalidade violada, mas homogeneidade de variâncias atendida.\")\n",
    "            recommendation = \"ANOVA robusta ou teste não-paramétrico (Kruskal-Wallis)\"\n",
    "        elif all_normal:\n",
    "            print(\"⚠️ Suposição de homogeneidade de variâncias violada, mas normalidade atendida.\")\n",
    "            recommendation = \"ANOVA com correção de Welch\"\n",
    "        else:\n",
    "            print(\"❌ Suposições de normalidade e homogeneidade de variâncias violadas.\")\n",
    "            recommendation = \"Teste não-paramétrico (Kruskal-Wallis)\"\n",
    "            \n",
    "        print(f\"Recomendação: {recommendation}\")\n",
    "        \n",
    "        return {\"normality\": all_normal, \"homoscedasticity\": homoscedasticity, \"recommendation\": recommendation}\n",
    "    \n",
    "    def visualize_data(self):\n",
    "        \"\"\"Gera visualizações detalhadas para exploração dos dados.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Dataset não foi carregado. Execute load_data() primeiro.\")\n",
    "        \n",
    "        # 1. Boxplots para cada variável por espécie\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, feature in enumerate(self.data.columns[:-1]):\n",
    "            sns.boxplot(x='species', y=feature, data=self.data, ax=axes[i], palette='viridis')\n",
    "            axes[i].set_title(f'Distribuição de {feature} por Espécie', fontsize=16)\n",
    "            axes[i].set_xlabel('Espécie', fontsize=14)\n",
    "            axes[i].set_ylabel(feature.replace('_', ' ').title(), fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Boxplots de Características por Espécie', fontsize=20, y=1.02)\n",
    "        plt.show()\n",
    "        \n",
    "        # 2. Matriz de dispersão colorida por espécie\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        sns.pairplot(self.data, hue='species', height=2.5, aspect=1.2, \n",
    "                     plot_kws={'alpha': 0.7, 's': 80, 'edgecolor': 'k', 'linewidth': 0.5},\n",
    "                     diag_kind='kde', palette='viridis')\n",
    "        plt.suptitle('Matriz de Dispersão de Características', fontsize=20, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # 3. Histogramas de distribuição para cada variável por espécie\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, feature in enumerate(self.data.columns[:-1]):\n",
    "            for species, color in zip(sorted(self.data['species'].unique()), \n",
    "                                      ['#440154', '#21918c', '#fde725']):\n",
    "                sns.kdeplot(self.data[self.data['species'] == species][feature], \n",
    "                           ax=axes[i], label=species, fill=True, alpha=0.3)\n",
    "                \n",
    "            axes[i].set_title(f'Distribuição de {feature.replace(\"_\", \" \").title()}', fontsize=16)\n",
    "            axes[i].set_xlabel(feature.replace('_', ' ').title(), fontsize=14)\n",
    "            axes[i].set_ylabel('Densidade', fontsize=14)\n",
    "            axes[i].legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('Distribuição das Características por Espécie', fontsize=20, y=1.02)\n",
    "        plt.show()\n",
    "\n",
    "# Instanciar e utilizar o gerenciador de dados\n",
    "data_mgr = DataManager(dataset_name=\"iris\")\n",
    "iris_df = data_mgr.load_data()\n",
    "data_mgr.summarize_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce085e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar os dados\n",
    "data_mgr.visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc138e9",
   "metadata": {},
   "source": [
    "## 4. Verificação de Suposições Estatísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a25f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar suposições para cada variável\n",
    "feature_assumptions = {}\n",
    "for feature in iris_df.columns[:-1]:\n",
    "    feature_assumptions[feature] = data_mgr.check_assumptions(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40fb44",
   "metadata": {},
   "source": [
    "## 5. Análise de Variância (ANOVA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727c409",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANOVAAnalyzer:\n",
    "    \"\"\"Classe para execução rigorosa de análises ANOVA.\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"Inicializa o analisador ANOVA com um dataset específico.\"\"\"\n",
    "        self.data = data\n",
    "        self.results = {}\n",
    "        \n",
    "    def run_oneway_anova(self, var_name, group_col='species', alpha=0.05):\n",
    "        \"\"\"Executa ANOVA unidirecional para uma variável específica.\"\"\"\n",
    "        print(f\"\\n--- ANOVA: {var_name} por {group_col} ---\\n\")\n",
    "        \n",
    "        # 1. ANOVA tradicional usando scipy.stats\n",
    "        groups = [self.data[self.data[group_col] == g][var_name].values \n",
    "                 for g in self.data[group_col].unique()]\n",
    "        \n",
    "        f_stat, p_value = stats.f_oneway(*groups)\n",
    "        significant = p_value < alpha\n",
    "        \n",
    "        print(f\"Resultado da ANOVA Unidirecional:\")\n",
    "        print(f\"F({len(groups)-1}, {self.data.shape[0]-len(groups)}) = {f_stat:.4f}, p = {p_value:.6f}\")\n",
    "        print(f\"Conclusão: {'Rejeitar H₀' if significant else 'Não rejeitar H₀'} (α = {alpha})\")\n",
    "        \n",
    "        if significant:\n",
    "            print(\"Há evidências estatísticas de diferenças entre pelo menos duas espécies.\")\n",
    "        else:\n",
    "            print(\"Não há evidências suficientes para afirmar diferenças entre as espécies.\")\n",
    "            \n",
    "        # 2. ANOVA usando statsmodels (permite tabela ANOVA detalhada)\n",
    "        formula = f\"{var_name} ~ C({group_col})\"\n",
    "        model = ols(formula, data=self.data).fit()\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "        \n",
    "        print(\"\\nTabela ANOVA Detalhada:\")\n",
    "        display(anova_table)\n",
    "        \n",
    "        # 3. Cálculo do tamanho do efeito (eta-squared)\n",
    "        ss_total = anova_table['sum_sq'].sum()\n",
    "        ss_between = anova_table['sum_sq'][0]\n",
    "        eta_squared = ss_between / ss_total\n",
    "        \n",
    "        # Interpretar tamanho do efeito\n",
    "        if eta_squared < 0.01:\n",
    "            effect_interpretation = \"negligenciável\"\n",
    "        elif eta_squared < 0.06:\n",
    "            effect_interpretation = \"pequeno\"\n",
    "        elif eta_squared < 0.14:\n",
    "            effect_interpretation = \"médio\"\n",
    "        else:\n",
    "            effect_interpretation = \"grande\"\n",
    "            \n",
    "        print(f\"\\nTamanho do Efeito:\")\n",
    "        print(f\"η² = {eta_squared:.4f} (efeito {effect_interpretation})\")\n",
    "        \n",
    "        # 4. Power analysis (potência do teste)\n",
    "        from statsmodels.stats.power import FTestAnovaPower\n",
    "        power_analysis = FTestAnovaPower()\n",
    "        groups_count = len(self.data[group_col].unique())\n",
    "        n_per_group = self.data.groupby(group_col).size().mean()\n",
    "        \n",
    "        # Calcular f_effect (Cohen's f) a partir de eta_squared\n",
    "        f_effect = np.sqrt(eta_squared / (1 - eta_squared))\n",
    "        \n",
    "        power = power_analysis.solve_power(\n",
    "            effect_size=f_effect,\n",
    "            nobs=self.data.shape[0],\n",
    "            k_groups=groups_count,\n",
    "            alpha=alpha\n",
    "        )\n",
    "        \n",
    "        print(f\"Potência do Teste: {power:.4f}\")\n",
    "        if power < 0.8:\n",
    "            print(f\"⚠️ Potência abaixo do recomendado (0.8). Há risco de erro Tipo II.\")\n",
    "            \n",
    "            # Calcular tamanho da amostra necessário para potência 0.8\n",
    "            required_n = power_analysis.solve_power(\n",
    "                effect_size=f_effect,\n",
    "                power=0.8,\n",
    "                k_groups=groups_count,\n",
    "                alpha=alpha\n",
    "            )\n",
    "            \n",
    "            print(f\"Para potência de 0.8, seriam necessárias aproximadamente {int(required_n)} observações totais.\")\n",
    "        else:\n",
    "            print(f\"✓ Potência adequada (>0.8). Baixo risco de erro Tipo II.\")\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        self.results[var_name] = {\n",
    "            'f_statistic': f_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': significant,\n",
    "            'eta_squared': eta_squared,\n",
    "            'effect_size_interpretation': effect_interpretation,\n",
    "            'power': power,\n",
    "            'model': model,\n",
    "            'anova_table': anova_table\n",
    "        }\n",
    "        \n",
    "        return self.results[var_name]\n",
    "    \n",
    "    def run_welch_anova(self, var_name, group_col='species', alpha=0.05):\n",
    "        \"\"\"Executa ANOVA de Welch (robusta a heterocedasticidade).\"\"\"\n",
    "        print(f\"\\n--- ANOVA de Welch: {var_name} por {group_col} ---\\n\")\n",
    "        \n",
    "        # Preparar dados\n",
    "        groups = self.data[group_col].unique()\n",
    "        data_by_group = [self.data[self.data[group_col] == g][var_name] for g in groups]\n",
    "        \n",
    "        # Executar teste de Welch\n",
    "        welch_results = stats.welch_anova(data_by_group)\n",
    "        \n",
    "        significant = welch_results[1] < alpha\n",
    "        \n",
    "        print(f\"Resultado da ANOVA de Welch:\")\n",
    "        print(f\"F({len(groups)-1}, {welch_results[2]:.2f}) = {welch_results[0]:.4f}, p = {welch_results[1]:.6f}\")\n",
    "        print(f\"Conclusão: {'Rejeitar H₀' if significant else 'Não rejeitar H₀'} (α = {alpha})\")\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        self.results[f\"{var_name}_welch\"] = {\n",
    "            'f_statistic': welch_results[0],\n",
    "            'p_value': welch_results[1],\n",
    "            'significant': significant,\n",
    "            'df_num': len(groups) - 1,\n",
    "            'df_denom': welch_results[2]\n",
    "        }\n",
    "        \n",
    "        return self.results[f\"{var_name}_welch\"]\n",
    "    \n",
    "    def run_kruskal_wallis(self, var_name, group_col='species', alpha=0.05):\n",
    "        \"\"\"Executa teste não-paramétrico de Kruskal-Wallis.\"\"\"\n",
    "        print(f\"\\n--- Teste de Kruskal-Wallis: {var_name} por {group_col} ---\\n\")\n",
    "        \n",
    "        # Preparar dados\n",
    "        groups = self.data[group_col].unique()\n",
    "        data_by_group = [self.data[self.data[group_col] == g][var_name] for g in groups]\n",
    "        \n",
    "        # Executar teste\n",
    "        H_stat, p_value = stats.kruskal(*data_by_group)\n",
    "        significant = p_value < alpha\n",
    "        \n",
    "        print(f\"Resultado do Teste de Kruskal-Wallis:\")\n",
    "        print(f\"H = {H_stat:.4f}, p = {p_value:.6f}\")\n",
    "        print(f\"Conclusão: {'Rejeitar H₀' if significant else 'Não rejeitar H₀'} (α = {alpha})\")\n",
    "        \n",
    "        # Calcular epsilon-squared como medida de tamanho de efeito\n",
    "        n = len(self.data)\n",
    "        epsilon_squared = (H_stat - len(groups) + 1) / (n - len(groups))\n",
    "        \n",
    "        # Interpretar tamanho de efeito\n",
    "        if epsilon_squared < 0.01:\n",
    "            effect_interpretation = \"negligenciável\"\n",
    "        elif epsilon_squared < 0.06:\n",
    "            effect_interpretation = \"pequeno\"\n",
    "        elif epsilon_squared < 0.14:\n",
    "            effect_interpretation = \"médio\"\n",
    "        else:\n",
    "            effect_interpretation = \"grande\"\n",
    "            \n",
    "        print(f\"\\nTamanho do Efeito:\")\n",
    "        print(f\"ε² = {epsilon_squared:.4f} (efeito {effect_interpretation})\")\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        self.results[f\"{var_name}_kruskal\"] = {\n",
    "            'h_statistic': H_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': significant,\n",
    "            'epsilon_squared': epsilon_squared,\n",
    "            'effect_size_interpretation': effect_interpretation\n",
    "        }\n",
    "        \n",
    "        return self.results[f\"{var_name}_kruskal\"]\n",
    "    \n",
    "    def post_hoc_tukey(self, var_name, group_col='species', alpha=0.05):\n",
    "        \"\"\"Executa teste post-hoc de Tukey HSD.\"\"\"\n",
    "        if var_name not in self.results:\n",
    "            raise ValueError(f\"ANOVA para {var_name} não foi executada. Execute run_oneway_anova primeiro.\")\n",
    "        \n",
    "        if not self.results[var_name]['significant']:\n",
    "            print(f\"\\nNota: ANOVA para {var_name} não foi significativa (p = {self.results[var_name]['p_value']:.4f}).\")\n",
    "            print(\"Testes post-hoc não são necessários, mas serão apresentados para fins didáticos.\")\n",
    "        \n",
    "        print(f\"\\n--- Teste Post-hoc de Tukey HSD: {var_name} ---\\n\")\n",
    "        \n",
    "        # Executar teste de Tukey\n",
    "        mc = MultiComparison(self.data[var_name], self.data[group_col])\n",
    "        tukey_result = mc.tukeyhsd(alpha=alpha)\n",
    "        \n",
    "        print(\"Resultado do Teste de Tukey HSD:\")\n",
    "        print(tukey_result)\n",
    "        \n",
    "        # Matriz de p-valores em formato tabular\n",
    "        try:\n",
    "            print(\"\\nMatriz de p-valores ajustados:\")\n",
    "            print(mc.groupsunique)\n",
    "            print(tukey_result.pvalues)\n",
    "        except:\n",
    "            print(\"\\nNota: Matriz de p-valores não disponível.\")\n",
    "        \n",
    "        # Plotar resultado\n",
    "        fig = plt.figure(figsize=(10, 6))\n",
    "        tukey_result.plot_simultaneous(ax=plt.gca(), figsize=(10, 6))\n",
    "        plt.title(f'Intervalos de Confiança (95%) para Diferenças em {var_name}', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        self.results[f\"{var_name}_tukey\"] = {\n",
    "            'tukey_result': tukey_result\n",
    "        }\n",
    "        \n",
    "        return tukey_result\n",
    "\n",
    "# Instanciar e utilizar o analisador ANOVA\n",
    "anova_analyzer = ANOVAAnalyzer(iris_df)\n",
    "\n",
    "# Executar ANOVA para comprimento da pétala\n",
    "anova_analyzer.run_oneway_anova('petal_length')\n",
    "anova_analyzer.post_hoc_tukey('petal_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960c8021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar ANOVA para largura da pétala\n",
    "anova_analyzer.run_oneway_anova('petal_width')\n",
    "anova_analyzer.post_hoc_tukey('petal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc610acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar ANOVA para comprimento da sépala\n",
    "anova_analyzer.run_oneway_anova('sepal_length')\n",
    "anova_analyzer.post_hoc_tukey('sepal_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d07d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar ANOVA para largura da sépala\n",
    "anova_analyzer.run_oneway_anova('sepal_width')\n",
    "anova_analyzer.post_hoc_tukey('sepal_width')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f5d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar análises alternativas para variáveis que não atendem às suposições\n",
    "for feature, assumption in feature_assumptions.items():\n",
    "    if not (assumption['normality'] and assumption['homoscedasticity']):\n",
    "        print(f\"\\n--- Análise Alternativa para {feature} ---\")\n",
    "        print(f\"Recomendação: {assumption['recommendation']}\")\n",
    "        \n",
    "        if assumption['recommendation'] == 'ANOVA com correção de Welch':\n",
    "            anova_analyzer.run_welch_anova(feature)\n",
    "        elif 'não-paramétrico' in assumption['recommendation']:\n",
    "            anova_analyzer.run_kruskal_wallis(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9299bc45",
   "metadata": {},
   "source": [
    "## 6. Visualização dos Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultVisualizer:\n",
    "    \"\"\"Classe para visualização profissional dos resultados de ANOVA.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, anova_results):\n",
    "        \"\"\"Inicializa o visualizador com dados e resultados de ANOVA.\"\"\"\n",
    "        self.data = data\n",
    "        self.results = anova_results\n",
    "    \n",
    "    def plot_means_with_ci(self, var_name, group_col='species'):\n",
    "        \"\"\"Plota médias com intervalos de confiança por grupo.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        # Estatísticas por grupo\n",
    "        groups = []\n",
    "        means = []\n",
    "        ci_low = []\n",
    "        ci_high = []\n",
    "        \n",
    "        for group in sorted(self.data[group_col].unique()):\n",
    "            group_data = self.data[self.data[group_col] == group][var_name]\n",
    "            groups.append(group)\n",
    "            \n",
    "            # Média\n",
    "            mean = group_data.mean()\n",
    "            means.append(mean)\n",
    "            \n",
    "            # Intervalo de confiança de 95%\n",
    "            ci = stats.t.interval(\n",
    "                0.95, \n",
    "                len(group_data) - 1, \n",
    "                loc=mean, \n",
    "                scale=stats.sem(group_data)\n",
    "            )\n",
    "            ci_low.append(ci[0])\n",
    "            ci_high.append(ci[1])\n",
    "        \n",
    "        # Plotar barras\n",
    "        x = np.arange(len(groups))\n",
    "        width = 0.6\n",
    "        \n",
    "        # Barras de erro com médias\n",
    "        bars = ax.bar(x, means, width, capsize=10, \n",
    "                     yerr=np.vstack((np.array(means) - np.array(ci_low), \n",
    "                                    np.array(ci_high) - np.array(means))),\n",
    "                     color=['#440154', '#21918c', '#fde725'], \n",
    "                     alpha=0.8, edgecolor='black', linewidth=1)\n",
    "        \n",
    "        # Adicionar valor da média\n",
    "        for i, bar in enumerate(bars):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                   f'{means[i]:.2f}', ha='center', va='bottom', fontsize=12)\n",
    "        \n",
    "        # Configurar eixos\n",
    "        ax.set_ylabel(var_name.replace('_', ' ').title(), fontsize=14)\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups, fontsize=12)\n",
    "        \n",
    "        # Adicionar título com resultados da ANOVA\n",
    "        if var_name in self.results:\n",
    "            result = self.results[var_name]\n",
    "            title = f\"Médias de {var_name.replace('_', ' ').title()} por Espécie\\n\"\n",
    "            title += f\"ANOVA: F({len(groups)-1}, {self.data.shape[0]-len(groups)}) = {result['f_statistic']:.2f}, \"\n",
    "            title += f\"p = {result['p_value']:.6f}, η² = {result['eta_squared']:.3f}\"\n",
    "            ax.set_title(title, fontsize=16)\n",
    "        else:\n",
    "            ax.set_title(f\"Médias de {var_name.replace('_', ' ').title()} por Espécie\", fontsize=16)\n",
    "        \n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_all_means(self):\n",
    "        \"\"\"Plota médias de todas as variáveis em um grid.\"\"\"\n",
    "        features = [col for col in self.data.columns if col != 'species']\n",
    "        \n",
    "        fig, axes = plt.subplots(2, 2, figsize=(18, 14))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, feature in enumerate(features):\n",
    "            ax = axes[i]\n",
    "            \n",
    "            # Dados para o gráfico\n",
    "            stats_by_group = self.data.groupby('species')[feature].agg(['mean', 'std', 'count'])\n",
    "            groups = stats_by_group.index\n",
    "            means = stats_by_group['mean'].values\n",
    "            \n",
    "            # Calcular erro padrão\n",
    "            std_err = stats_by_group['std'] / np.sqrt(stats_by_group['count'])\n",
    "            \n",
    "            # Calcular intervalo de confiança de 95%\n",
    "            ci_low = []\n",
    "            ci_high = []\n",
    "            \n",
    "            for j, group in enumerate(groups):\n",
    "                t_val = stats.t.ppf(0.975, stats_by_group['count'][j] - 1)\n",
    "                ci_low.append(means[j] - t_val * std_err[j])\n",
    "                ci_high.append(means[j] + t_val * std_err[j])\n",
    "            \n",
    "            # Plotar barras\n",
    "            x = np.arange(len(groups))\n",
    "            width = 0.6\n",
    "            \n",
    "            # Barras de erro com médias\n",
    "            bars = ax.bar(x, means, width, capsize=10, \n",
    "                         yerr=np.vstack((np.array(means) - np.array(ci_low), \n",
    "                                        np.array(ci_high) - np.array(means))),\n",
    "                         color=['#440154', '#21918c', '#fde725'], \n",
    "                         alpha=0.8, edgecolor='black', linewidth=1)\n",
    "            \n",
    "            # Adicionar valor da média\n",
    "            for j, bar in enumerate(bars):\n",
    "                height = bar.get_height()\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., height + 0.02*(ax.get_ylim()[1]-ax.get_ylim()[0]),\n",
    "                       f'{means[j]:.2f}', ha='center', va='bottom', fontsize=11)\n",
    "            \n",
    "            # Configurar eixos\n",
    "            ax.set_ylabel(feature.replace('_', ' ').title(), fontsize=14)\n",
    "            ax.set_xticks(x)\n",
    "            ax.set_xticklabels(groups, fontsize=12)\n",
    "            \n",
    "            # Adicionar título com resultados da ANOVA\n",
    "            if feature in self.results:\n",
    "                result = self.results[feature]\n",
    "                title = f\"{feature.replace('_', ' ').title()}\\n\"\n",
    "                title += f\"F = {result['f_statistic']:.1f}, p = {result['p_value']:.4f}\"\n",
    "                ax.set_title(title, fontsize=14)\n",
    "            else:\n",
    "                ax.set_title(feature.replace('_', ' ').title(), fontsize=14)\n",
    "            \n",
    "            ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.suptitle('Comparação de Médias entre Espécies', fontsize=20, y=0.98)\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.show()\n",
    "    \n",
    "    def summarize_results(self):\n",
    "        \"\"\"Sumariza os resultados de todas as análises em formato tabular.\"\"\"\n",
    "        # Coletar resultados\n",
    "        summary_data = []\n",
    "        \n",
    "        for var_name, result in self.results.items():\n",
    "            if var_name.endswith('_welch') or var_name.endswith('_kruskal') or var_name.endswith('_tukey'):\n",
    "                continue\n",
    "                \n",
    "            row = {\n",
    "                'Variável': var_name.replace('_', ' ').title(),\n",
    "                'F-valor': result['f_statistic'],\n",
    "                'p-valor': result['p_value'],\n",
    "                'Significância': 'Significativo' if result['significant'] else 'Não significativo',\n",
    "                'η²': result.get('eta_squared', None),\n",
    "                'Tamanho do Efeito': result.get('effect_size_interpretation', 'N/A'),\n",
    "                'Potência': result.get('power', None)\n",
    "            }\n",
    "            summary_data.append(row)\n",
    "        \n",
    "        # Criar DataFrame resumo\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        summary_df = summary_df.sort_values('p-valor')\n",
    "        \n",
    "        print(\"\\n=== Sumário dos Resultados da ANOVA ===\\n\")\n",
    "        display(summary_df.reset_index(drop=True))\n",
    "        \n",
    "        # Interpretação geral\n",
    "        print(\"\\nInterpretação Geral:\")\n",
    "        sig_vars = summary_df[summary_df['Significância'] == 'Significativo']['Variável'].tolist()\n",
    "        \n",
    "        if len(sig_vars) > 0:\n",
    "            print(f\"• As seguintes variáveis apresentam diferenças significativas entre espécies: {', '.join(sig_vars)}.\")\n",
    "            \n",
    "            # Identificar maior efeito\n",
    "            if 'η²' in summary_df.columns:\n",
    "                max_effect_var = summary_df.loc[summary_df['η²'].idxmax()]['Variável']\n",
    "                max_effect = summary_df.loc[summary_df['η²'].idxmax()]['η²']\n",
    "                print(f\"• A variável {max_effect_var} apresenta o maior efeito (η² = {max_effect:.4f}).\")\n",
    "        else:\n",
    "            print(\"• Nenhuma variável apresentou diferenças significativas entre espécies.\")\n",
    "            \n",
    "        # Plotar heatmap de significância\n",
    "        self.plot_significance_heatmap()\n",
    "            \n",
    "        return summary_df\n",
    "        \n",
    "    def plot_significance_heatmap(self):\n",
    "        \"\"\"Cria um mapa de calor de significância para comparações post-hoc.\"\"\"\n",
    "        # Verificar quais variáveis têm resultados Tukey\n",
    "        features_with_tukey = [var.replace('_tukey', '') \n",
    "                             for var in self.results.keys() \n",
    "                             if var.endswith('_tukey')]\n",
    "        \n",
    "        if not features_with_tukey:\n",
    "            print(\"Não há resultados post-hoc disponíveis para visualização.\")\n",
    "            return\n",
    "            \n",
    "        # Preparar dados para o heatmap\n",
    "        species = sorted(self.data['species'].unique())\n",
    "        n_species = len(species)\n",
    "        n_features = len(features_with_tukey)\n",
    "        \n",
    "        # Criar matrizes vazias\n",
    "        pvalues = np.ones((n_features, n_species, n_species)) * np.nan\n",
    "        significance = np.zeros((n_features, n_species, n_species), dtype=int)\n",
    "        \n",
    "        # Preencher com resultados\n",
    "        for f_idx, feature in enumerate(features_with_tukey):\n",
    "            if f\"{feature}_tukey\" in self.results:\n",
    "                tukey_result = self.results[f\"{feature}_tukey\"]['tukey_result']\n",
    "                \n",
    "                for i, group1 in enumerate(tukey_result.groupsunique):\n",
    "                    for j, group2 in enumerate(tukey_result.groupsunique):\n",
    "                        if i < j:  # Preencher apenas o triângulo superior\n",
    "                            # Encontrar índice de comparação\n",
    "                            comp_idx = None\n",
    "                            for k, (g1, g2, _) in enumerate(tukey_result._multicomp.pairindices):\n",
    "                                if (g1 == i and g2 == j) or (g1 == j and g2 == i):\n",
    "                                    comp_idx = k\n",
    "                                    break\n",
    "                            \n",
    "                            if comp_idx is not None:\n",
    "                                p_value = tukey_result.pvalues[comp_idx]\n",
    "                                pvalues[f_idx, i, j] = p_value\n",
    "                                pvalues[f_idx, j, i] = p_value  # Simetria\n",
    "                                \n",
    "                                # Codificar significância: 0=NS, 1=p<0.05, 2=p<0.01, 3=p<0.001\n",
    "                                if p_value < 0.001:\n",
    "                                    sig_code = 3\n",
    "                                elif p_value < 0.01:\n",
    "                                    sig_code = 2\n",
    "                                elif p_value < 0.05:\n",
    "                                    sig_code = 1\n",
    "                                else:\n",
    "                                    sig_code = 0\n",
    "                                    \n",
    "                                significance[f_idx, i, j] = sig_code\n",
    "                                significance[f_idx, j, i] = sig_code  # Simetria\n",
    "        \n",
    "        # Plotar heatmaps\n",
    "        fig, axes = plt.subplots(1, n_features, figsize=(5*n_features, 5))\n",
    "        if n_features == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        # Mapa de cores para significância\n",
    "        cmap = plt.cm.get_cmap('YlOrRd', 4)\n",
    "        \n",
    "        for f_idx, (feature, ax) in enumerate(zip(features_with_tukey, axes)):\n",
    "            # Criar matriz para plotar\n",
    "            sig_matrix = pd.DataFrame(significance[f_idx], \n",
    "                                     index=species, \n",
    "                                     columns=species)\n",
    "            \n",
    "            # Plot heatmap\n",
    "            sns.heatmap(sig_matrix, annot=True, cmap=cmap, \n",
    "                       cbar_kws={'ticks': [0, 1, 2, 3]},\n",
    "                       vmin=0, vmax=3, ax=ax, fmt='d')\n",
    "            \n",
    "            # Configurações\n",
    "            ax.set_title(f\"{feature.replace('_', ' ').title()}\")\n",
    "            \n",
    "            # Ajustar diagonais\n",
    "            for i in range(len(species)):\n",
    "                sig_matrix.iloc[i, i] = np.nan\n",
    "        \n",
    "        # Adicionar legenda de cores\n",
    "        plt.tight_layout()\n",
    "        fig.subplots_adjust(bottom=0.2)\n",
    "        \n",
    "        # Legenda personalizada\n",
    "        legend_labels = [\"NS: p≥0.05\", \"*: p<0.05\", \"**: p<0.01\", \"***: p<0.001\"]\n",
    "        custom_lines = [plt.Line2D([0], [0], color=cmap(i/3), lw=7) for i in range(4)]\n",
    "        fig.legend(custom_lines, legend_labels, loc='lower center', ncol=4, fontsize=12)\n",
    "        \n",
    "        plt.suptitle(\"Significância das Diferenças entre Espécies (Tukey HSD)\", fontsize=18, y=1.05)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Criar e utilizar o visualizador de resultados\n",
    "visualizer = ResultVisualizer(iris_df, anova_analyzer.results)\n",
    "visualizer.plot_all_means()\n",
    "visualizer.summarize_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae96aa71",
   "metadata": {},
   "source": [
    "## 7. Análise de Componentes Principais (PCA)\n",
    "\n",
    "Como análise complementar, podemos visualizar o agrupamento das espécies usando PCA para verificar como as diferenças identificadas pela ANOVA se manifestam em termos de variabilidade multivariada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5e79b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Preparar dados para PCA\n",
    "X = iris_df.iloc[:, :-1].values  # Todas as features\n",
    "y = iris_df['species'].values    # Classes\n",
    "\n",
    "# Padronizar os dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Variância explicada\n",
    "explained_variance = pca.explained_variance_ratio_ * 100\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Plotar variância explicada\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.8, \n",
    "       color='skyblue', edgecolor='black', label='Variância individual')\n",
    "plt.step(range(1, len(cumulative_variance) + 1), cumulative_variance, where='mid', \n",
    "        color='red', label='Variância acumulada')\n",
    "plt.axhline(y=95, color='k', linestyle='--', alpha=0.5, label='Limite 95%')\n",
    "plt.xlabel('Componentes Principais', fontsize=14)\n",
    "plt.ylabel('% de Variância Explicada', fontsize=14)\n",
    "plt.title('Variância Explicada por Componente Principal', fontsize=16)\n",
    "plt.xticks(range(1, len(explained_variance) + 1))\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotar os resultados do PCA (primeiros 2 componentes)\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Cores por espécie\n",
    "colors = {'setosa': '#440154', 'versicolor': '#21918c', 'virginica': '#fde725'}\n",
    "\n",
    "# Plotar pontos\n",
    "for species in np.unique(y):\n",
    "    plt.scatter(X_pca[y == species, 0], X_pca[y == species, 1], s=100, alpha=0.8,\n",
    "               edgecolor='k', linewidth=1, color=colors[species], label=species)\n",
    "\n",
    "# Adicionar vetores de features\n",
    "features = iris_df.columns[:-1]\n",
    "for i, feature in enumerate(features):\n",
    "    plt.arrow(0, 0, pca.components_[0, i]*7, pca.components_[1, i]*7,\n",
    "             head_width=0.2, head_length=0.2, fc='k', ec='k')\n",
    "    plt.text(pca.components_[0, i]*7.5, pca.components_[1, i]*7.5, feature,\n",
    "            fontsize=14)\n",
    "\n",
    "# Adicionar círculo de correlações\n",
    "circle = plt.Circle((0, 0), 1, fill=False, color='gray', linestyle='--')\n",
    "plt.gca().add_patch(circle)\n",
    "\n",
    "# Configurações do gráfico\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.1f}%)', fontsize=14)\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.1f}%)', fontsize=14)\n",
    "plt.title('Análise de Componentes Principais: Espécies de Íris', fontsize=18)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=14)\n",
    "\n",
    "# Ajustar limites para incluir vetores e rótulos\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Exibir coeficientes (loadings) dos componentes principais\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(pca.components_.shape[0])],\n",
    "    index=features\n",
    ")\n",
    "print(\"Coeficientes dos Componentes Principais (loadings):\")\n",
    "display(loadings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7007dbb7",
   "metadata": {},
   "source": [
    "## 8. Conclusões e Interpretação Biológica\n",
    "\n",
    "### 8.1 Síntese dos Resultados\n",
    "\n",
    "1. **Diferenças Morfológicas**:\n",
    "   - As características da pétala (comprimento e largura) exibem as diferenças mais pronunciadas entre espécies (tamanho de efeito grande)\n",
    "   - O comprimento da sépala também apresenta diferenças significativas entre as três espécies\n",
    "   - A largura da sépala exibe o menor poder discriminatório, embora ainda apresente diferenças significativas\n",
    "\n",
    "2. **Padrões de Variabilidade**:\n",
    "   - *Iris setosa* mostra clara separação morfológica das outras duas espécies\n",
    "   - *Iris versicolor* e *Iris virginica* apresentam alguma sobreposição, especialmente nas características da sépala\n",
    "   - A análise PCA confirma essa separação, com os dois primeiros componentes explicando aproximadamente 95% da variância\n",
    "\n",
    "3. **Importância Taxonômica**:\n",
    "   - O comprimento da pétala emerge como o indicador mais confiável para classificação taxonômica destas espécies\n",
    "   - Combinações de características, conforme mostrado pela PCA, oferecem maior poder discriminatório que características isoladas\n",
    "\n",
    "### 8.2 Limitações do Estudo\n",
    "\n",
    "1. O tamanho amostral, embora adequado para ANOVA (potência > 0.8), poderia ser ampliado para capturar maior variabilidade intraespecífica\n",
    "2. As características analisadas limitam-se a medidas morfológicas; análises adicionais poderiam incluir características ecológicas ou genéticas\n",
    "3. A presença de alguns outliers pode influenciar ligeiramente as estatísticas paramétricas\n",
    "\n",
    "### 8.3 Recomendações e Estudos Futuros\n",
    "\n",
    "1. Desenvolver modelos de classificação baseados nas diferenças morfométricas identificadas\n",
    "2. Investigar correlações entre características morfológicas e fatores ecológicos (habitat, polinizadores)\n",
    "3. Expandir a análise para incluir mais espécies do gênero Iris e explorar relações filogenéticas\n",
    "4. Aplicar técnicas de morfometria geométrica para análise mais detalhada da forma das pétalas e sépalas\n",
    "\n",
    "A análise ANOVA fornece evidências estatísticas robustas de que as três espécies de íris são morfologicamente distintas, corroborando a classificação taxonômica de Fisher e demonstrando a utilidade das técnicas de análise de variância em estudos de biodiversidade vegetal."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
