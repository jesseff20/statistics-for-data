{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2b84ca4",
   "metadata": {},
   "source": [
    "# Teste t para Análise de Campanhas A/B\n",
    "\n",
    "**Autor:** Jesse Fernandes\n",
    "\n",
    "**Data:** 2025-09-29\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Este notebook demonstra uma implementação profissional de testes t para análise de campanhas A/B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f7a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importações básicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Union, Any\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.power import TTestIndPower, TTestPower\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "@dataclass\n",
    "class TTestResult:\n",
    "    \"\"\"Classe para armazenar os resultados de um teste t.\"\"\"\n",
    "    t_stat: float\n",
    "    p_value: float\n",
    "    mean_diff: float\n",
    "    ci_low: float\n",
    "    ci_high: float\n",
    "    df: float\n",
    "    test_type: str\n",
    "    equal_var: bool = True\n",
    "    effect_size: Optional[float] = None\n",
    "    effect_size_type: Optional[str] = None\n",
    "    normality_test: Optional[Dict[str, Dict[str, float]]] = None\n",
    "    homogeneity_test: Optional[Dict[str, float]] = None\n",
    "    \n",
    "    def is_significant(self, alpha: float = 0.05) -> bool:\n",
    "        \"\"\"Verifica se o resultado é estatisticamente significativo.\"\"\"\n",
    "        return self.p_value < alpha\n",
    "    \n",
    "    def summary(self) -> str:\n",
    "        \"\"\"Retorna um resumo textual do resultado do teste.\"\"\"\n",
    "        sig_str = \"é\" if self.is_significant() else \"não é\"\n",
    "        \n",
    "        summary_text = [\n",
    "            f\"Tipo de teste: {self.test_type}\",\n",
    "            f\"Estatística t: {self.t_stat:.4f}\",\n",
    "            f\"Valor-p: {self.p_value:.4f}\",\n",
    "            f\"Diferença média: {self.mean_diff:.4f}\",\n",
    "            f\"Intervalo de confiança (95%): [{self.ci_low:.4f}, {self.ci_high:.4f}]\",\n",
    "            f\"Graus de liberdade: {self.df:.1f}\",\n",
    "            f\"Resultado: A diferença {sig_str} estatisticamente significativa (α = 0.05).\"\n",
    "        ]\n",
    "        \n",
    "        if self.effect_size is not None:\n",
    "            summary_text.append(f\"Tamanho do efeito ({self.effect_size_type}): {self.effect_size:.4f}\")\n",
    "            \n",
    "        return \"\\n\".join(summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa19dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CampaignDataManager:\n",
    "    \"\"\"Classe para gerenciar dados de campanhas A/B.\"\"\"\n",
    "    \n",
    "    def __init__(self, data: Optional[pd.DataFrame] = None, group_col: str = 'group', \n",
    "                 metric_col: str = 'metric', group_a: str = 'A', group_b: str = 'B'):\n",
    "        \"\"\"Inicializa o gerenciador de dados de campanhas A/B.\n",
    "        \n",
    "        Args:\n",
    "            data: DataFrame com os dados da campanha\n",
    "            group_col: Nome da coluna que identifica os grupos (A/B)\n",
    "            metric_col: Nome da coluna que contém a métrica de resultado\n",
    "            group_a: Valor que identifica o grupo A\n",
    "            group_b: Valor que identifica o grupo B\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.group_col = group_col\n",
    "        self.metric_col = metric_col\n",
    "        self.group_a = group_a\n",
    "        self.group_b = group_b\n",
    "        \n",
    "    def load_data(self, file_path: str) -> 'CampaignDataManager':\n",
    "        \"\"\"Carrega dados de um arquivo CSV.\"\"\"\n",
    "        self.data = pd.read_csv(file_path)\n",
    "        return self\n",
    "    \n",
    "    def generate_synthetic_data(self, n_samples_a: int = 500, n_samples_b: int = 500, \n",
    "                               mean_a: float = 50, mean_b: float = 55, \n",
    "                               std_a: float = 10, std_b: float = 10) -> 'CampaignDataManager':\n",
    "        \"\"\"Gera dados sintéticos para uma campanha A/B.\n",
    "        \n",
    "        Args:\n",
    "            n_samples_a: Número de amostras para o grupo A\n",
    "            n_samples_b: Número de amostras para o grupo B\n",
    "            mean_a: Média do grupo A\n",
    "            mean_b: Média do grupo B\n",
    "            std_a: Desvio padrão do grupo A\n",
    "            std_b: Desvio padrão do grupo B\n",
    "        \"\"\"\n",
    "        group_a_data = np.random.normal(mean_a, std_a, n_samples_a)\n",
    "        group_b_data = np.random.normal(mean_b, std_b, n_samples_b)\n",
    "        \n",
    "        self.data = pd.DataFrame({\n",
    "            self.group_col: [self.group_a] * n_samples_a + [self.group_b] * n_samples_b,\n",
    "            self.metric_col: np.concatenate([group_a_data, group_b_data])\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def get_group_data(self, group: str) -> np.ndarray:\n",
    "        \"\"\"Retorna os dados de um grupo específico.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Dados não carregados. Use load_data() ou generate_synthetic_data().\")\n",
    "        \n",
    "        return self.data[self.data[self.group_col] == group][self.metric_col].values\n",
    "    \n",
    "    def get_groups_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Retorna os dados dos grupos A e B.\"\"\"\n",
    "        return self.get_group_data(self.group_a), self.get_group_data(self.group_b)\n",
    "    \n",
    "    def get_summary_statistics(self) -> pd.DataFrame:\n",
    "        \"\"\"Retorna estatísticas descritivas por grupo.\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"Dados não carregados. Use load_data() ou generate_synthetic_data().\")\n",
    "        \n",
    "        return self.data.groupby(self.group_col)[self.metric_col].agg([\n",
    "            'count', 'mean', 'std', 'min', 'median', 'max',\n",
    "            lambda x: np.percentile(x, 25),\n",
    "            lambda x: np.percentile(x, 75)\n",
    "        ]).rename(columns={'<lambda_0>': 'q1', '<lambda_1>': 'q3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da889b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTestAnalyzer:\n",
    "    \"\"\"Classe para realizar testes t e verificar pressupostos.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_manager: CampaignDataManager):\n",
    "        \"\"\"Inicializa o analisador de testes t.\n",
    "        \n",
    "        Args:\n",
    "            data_manager: Instância de CampaignDataManager com os dados da campanha\n",
    "        \"\"\"\n",
    "        self.data_manager = data_manager\n",
    "        \n",
    "    def check_normality(self, method: str = 'shapiro') -> Dict[str, Dict[str, float]]:\n",
    "        \"\"\"Verifica a normalidade dos dados em cada grupo.\n",
    "        \n",
    "        Args:\n",
    "            method: Método para teste de normalidade ('shapiro', 'ks', 'anderson')\n",
    "            \n",
    "        Returns:\n",
    "            Dicionário com resultados do teste de normalidade por grupo\n",
    "        \"\"\"\n",
    "        group_a_data, group_b_data = self.data_manager.get_groups_data()\n",
    "        results = {}\n",
    "        \n",
    "        for name, data in [(self.data_manager.group_a, group_a_data), \n",
    "                           (self.data_manager.group_b, group_b_data)]:\n",
    "            if method == 'shapiro':\n",
    "                stat, p_value = stats.shapiro(data)\n",
    "                results[name] = {'statistic': stat, 'p_value': p_value}\n",
    "            elif method == 'ks':\n",
    "                stat, p_value = stats.kstest(data, 'norm', args=(np.mean(data), np.std(data)))\n",
    "                results[name] = {'statistic': stat, 'p_value': p_value}\n",
    "            elif method == 'anderson':\n",
    "                result = stats.anderson(data, 'norm')\n",
    "                results[name] = {'statistic': result.statistic, 'critical_values': result.critical_values}\n",
    "            else:\n",
    "                raise ValueError(f\"Método '{method}' não suportado. Use 'shapiro', 'ks', ou 'anderson'.\")\n",
    "                \n",
    "        return results\n",
    "    \n",
    "    def check_homogeneity_of_variance(self) -> Dict[str, float]:\n",
    "        \"\"\"Verifica a homogeneidade das variâncias entre os grupos.\n",
    "        \n",
    "        Returns:\n",
    "            Dicionário com resultado do teste de Levene\n",
    "        \"\"\"\n",
    "        group_a_data, group_b_data = self.data_manager.get_groups_data()\n",
    "        stat, p_value = stats.levene(group_a_data, group_b_data)\n",
    "        return {'statistic': stat, 'p_value': p_value}\n",
    "    \n",
    "    def run_independent_ttest(self, equal_var: bool = True, alpha: float = 0.05) -> TTestResult:\n",
    "        \"\"\"Realiza um teste t para amostras independentes.\n",
    "        \n",
    "        Args:\n",
    "            equal_var: Se True, assume variâncias iguais (teste t de Student),\n",
    "                      caso contrário, usa o teste t de Welch\n",
    "            alpha: Nível de significância\n",
    "            \n",
    "        Returns:\n",
    "            Objeto TTestResult com os resultados do teste\n",
    "        \"\"\"\n",
    "        group_a_data, group_b_data = self.data_manager.get_groups_data()\n",
    "        \n",
    "        # Verifica pressupostos\n",
    "        normality_test = self.check_normality()\n",
    "        homogeneity_test = self.check_homogeneity_of_variance()\n",
    "        \n",
    "        # Se falhar no teste de homogeneidade das variâncias, sugere usar equal_var=False\n",
    "        if homogeneity_test['p_value'] < alpha and equal_var:\n",
    "            warnings.warn(\"As variâncias não são homogêneas. Considere usar equal_var=False para o teste t de Welch.\")\n",
    "        \n",
    "        # Realiza o teste t\n",
    "        t_stat, p_value = stats.ttest_ind(group_a_data, group_b_data, equal_var=equal_var)\n",
    "        \n",
    "        # Calcula diferença média e intervalo de confiança\n",
    "        mean_diff = np.mean(group_a_data) - np.mean(group_b_data)\n",
    "        \n",
    "        if equal_var:\n",
    "            # Graus de liberdade para variâncias iguais\n",
    "            df = len(group_a_data) + len(group_b_data) - 2\n",
    "            # Pooled standard deviation\n",
    "            s_pooled = np.sqrt(((len(group_a_data) - 1) * np.var(group_a_data, ddof=1) + \n",
    "                               (len(group_b_data) - 1) * np.var(group_b_data, ddof=1)) / df)\n",
    "            # Standard error of difference between means\n",
    "            se_diff = s_pooled * np.sqrt(1/len(group_a_data) + 1/len(group_b_data))\n",
    "            test_type = \"Teste t de Student para amostras independentes\"\n",
    "        else:\n",
    "            # Graus de liberdade para variâncias desiguais (aproximação de Welch-Satterthwaite)\n",
    "            var_a = np.var(group_a_data, ddof=1)\n",
    "            var_b = np.var(group_b_data, ddof=1)\n",
    "            n_a = len(group_a_data)\n",
    "            n_b = len(group_b_data)\n",
    "            \n",
    "            df = ((var_a/n_a + var_b/n_b)**2) / ((var_a/n_a)**2/(n_a-1) + (var_b/n_b)**2/(n_b-1))\n",
    "            # Standard error of difference between means\n",
    "            se_diff = np.sqrt(var_a/n_a + var_b/n_b)\n",
    "            test_type = \"Teste t de Welch para amostras independentes\"\n",
    "            \n",
    "        # Intervalo de confiança\n",
    "        t_crit = stats.t.ppf(1 - alpha/2, df)\n",
    "        ci_low = mean_diff - t_crit * se_diff\n",
    "        ci_high = mean_diff + t_crit * se_diff\n",
    "        \n",
    "        # Tamanho do efeito (d de Cohen)\n",
    "        effect_size = mean_diff / np.sqrt((np.var(group_a_data, ddof=1) + np.var(group_b_data, ddof=1)) / 2)\n",
    "        \n",
    "        return TTestResult(\n",
    "            t_stat=t_stat,\n",
    "            p_value=p_value,\n",
    "            mean_diff=mean_diff,\n",
    "            ci_low=ci_low,\n",
    "            ci_high=ci_high,\n",
    "            df=df,\n",
    "            test_type=test_type,\n",
    "            equal_var=equal_var,\n",
    "            effect_size=effect_size,\n",
    "            effect_size_type=\"d de Cohen\",\n",
    "            normality_test=normality_test,\n",
    "            homogeneity_test=homogeneity_test\n",
    "        )\n",
    "        \n",
    "    def run_paired_ttest(self, alpha: float = 0.05) -> TTestResult:\n",
    "        \"\"\"Realiza um teste t para amostras pareadas.\n",
    "        \n",
    "        Args:\n",
    "            alpha: Nível de significância\n",
    "            \n",
    "        Returns:\n",
    "            Objeto TTestResult com os resultados do teste\n",
    "        \"\"\"\n",
    "        group_a_data, group_b_data = self.data_manager.get_groups_data()\n",
    "        \n",
    "        if len(group_a_data) != len(group_b_data):\n",
    "            raise ValueError(\"Grupos devem ter o mesmo tamanho para teste t pareado.\")\n",
    "        \n",
    "        # Verifica normalidade das diferenças\n",
    "        differences = group_a_data - group_b_data\n",
    "        _, p_value_norm = stats.shapiro(differences)\n",
    "        normality_test = {'differences': {'statistic': _, 'p_value': p_value_norm}}\n",
    "        \n",
    "        # Realiza o teste t pareado\n",
    "        t_stat, p_value = stats.ttest_rel(group_a_data, group_b_data)\n",
    "        \n",
    "        # Calcula diferença média e intervalo de confiança\n",
    "        mean_diff = np.mean(differences)\n",
    "        df = len(differences) - 1\n",
    "        std_diff = np.std(differences, ddof=1)\n",
    "        se_diff = std_diff / np.sqrt(len(differences))\n",
    "        \n",
    "        # Intervalo de confiança\n",
    "        t_crit = stats.t.ppf(1 - alpha/2, df)\n",
    "        ci_low = mean_diff - t_crit * se_diff\n",
    "        ci_high = mean_diff + t_crit * se_diff\n",
    "        \n",
    "        # Tamanho do efeito (d de Cohen para medidas repetidas)\n",
    "        effect_size = mean_diff / std_diff\n",
    "        \n",
    "        return TTestResult(\n",
    "            t_stat=t_stat,\n",
    "            p_value=p_value,\n",
    "            mean_diff=mean_diff,\n",
    "            ci_low=ci_low,\n",
    "            ci_high=ci_high,\n",
    "            df=df,\n",
    "            test_type=\"Teste t pareado\",\n",
    "            effect_size=effect_size,\n",
    "            effect_size_type=\"d de Cohen (medidas repetidas)\",\n",
    "            normality_test=normality_test,\n",
    "            homogeneity_test=None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e456b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PowerAnalyzer:\n",
    "    \"\"\"Classe para análise de poder estatístico e cálculo de tamanho amostral.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.05):\n",
    "        \"\"\"Inicializa o analisador de poder estatístico.\n",
    "        \n",
    "        Args:\n",
    "            alpha: Nível de significância\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.power_analyzer = TTestIndPower()\n",
    "        \n",
    "    def cohen_d_interpretation(self, d: float) -> str:\n",
    "        \"\"\"Interpreta o valor do d de Cohen.\"\"\"\n",
    "        if abs(d) < 0.2:\n",
    "            return \"Muito pequeno\"\n",
    "        elif abs(d) < 0.5:\n",
    "            return \"Pequeno\"\n",
    "        elif abs(d) < 0.8:\n",
    "            return \"Médio\"\n",
    "        else:\n",
    "            return \"Grande\"\n",
    "    \n",
    "    def calculate_power(self, effect_size: float, n1: int, n2: Optional[int] = None) -> float:\n",
    "        \"\"\"Calcula o poder estatístico para um teste t independente.\n",
    "        \n",
    "        Args:\n",
    "            effect_size: Tamanho do efeito (d de Cohen)\n",
    "            n1: Tamanho da amostra do grupo 1\n",
    "            n2: Tamanho da amostra do grupo 2 (se None, assume igual a n1)\n",
    "            \n",
    "        Returns:\n",
    "            Poder estatístico (0-1)\n",
    "        \"\"\"\n",
    "        if n2 is None:\n",
    "            n2 = n1\n",
    "            \n",
    "        # Tamanho da amostra harmônica média\n",
    "        nobs = 2 / (1/n1 + 1/n2)\n",
    "        \n",
    "        return self.power_analyzer.power(effect_size=effect_size, nobs=nobs, alpha=self.alpha)\n",
    "    \n",
    "    def calculate_sample_size(self, effect_size: float, power: float = 0.8) -> int:\n",
    "        \"\"\"Calcula o tamanho amostral necessário para detectar um efeito.\n",
    "        \n",
    "        Args:\n",
    "            effect_size: Tamanho do efeito (d de Cohen)\n",
    "            power: Poder estatístico desejado (geralmente 0.8)\n",
    "            \n",
    "        Returns:\n",
    "            Tamanho da amostra necessário para cada grupo\n",
    "        \"\"\"\n",
    "        nobs = self.power_analyzer.solve_power(effect_size=effect_size, power=power, alpha=self.alpha)\n",
    "        return int(np.ceil(nobs))\n",
    "    \n",
    "    def plot_power_analysis(self, effect_sizes: List[float], ns: List[int], \n",
    "                           highlight_power: float = 0.8) -> plt.Figure:\n",
    "        \"\"\"Plota uma curva de poder estatístico para diferentes tamanhos de efeito e tamanhos de amostra.\n",
    "        \n",
    "        Args:\n",
    "            effect_sizes: Lista de tamanhos de efeito a serem considerados\n",
    "            ns: Lista de tamanhos de amostra a serem considerados\n",
    "            highlight_power: Valor de poder a ser destacado (geralmente 0.8)\n",
    "            \n",
    "        Returns:\n",
    "            Figura com o gráfico de poder estatístico\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        for effect_size in effect_sizes:\n",
    "            powers = [self.calculate_power(effect_size, n) for n in ns]\n",
    "            ax.plot(ns, powers, '-o', label=f'd = {effect_size:.2f} ({self.cohen_d_interpretation(effect_size)})')\n",
    "            \n",
    "        # Linha horizontal para destacar o poder desejado (geralmente 0.8)\n",
    "        ax.axhline(y=highlight_power, linestyle='--', color='gray', alpha=0.7)\n",
    "        ax.text(max(ns)*0.8, highlight_power+0.02, f'Poder = {highlight_power}', fontsize=12)\n",
    "        \n",
    "        # Formatação do gráfico\n",
    "        ax.set_xlabel('Tamanho da Amostra (por grupo)')\n",
    "        ax.set_ylabel('Poder Estatístico')\n",
    "        ax.set_title('Análise de Poder para Diferentes Tamanhos de Efeito e Tamanhos de Amostra')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(title='Tamanho do Efeito')\n",
    "        \n",
    "        ax.set_ylim(0, 1.05)\n",
    "        ax.set_xlim(0, max(ns)*1.05)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11ac632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultVisualizer:\n",
    "    \"\"\"Classe para visualização de resultados de testes t.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_manager: CampaignDataManager):\n",
    "        \"\"\"Inicializa o visualizador de resultados.\n",
    "        \n",
    "        Args:\n",
    "            data_manager: Instância de CampaignDataManager com os dados da campanha\n",
    "        \"\"\"\n",
    "        self.data_manager = data_manager\n",
    "        \n",
    "    def plot_distributions(self, kde: bool = True, rug: bool = True) -> plt.Figure:\n",
    "        \"\"\"Plota as distribuições dos grupos A e B.\n",
    "        \n",
    "        Args:\n",
    "            kde: Se True, inclui estimativa de densidade kernel\n",
    "            rug: Se True, inclui marcações no eixo x para cada observação\n",
    "            \n",
    "        Returns:\n",
    "            Figura com gráficos de distribuição\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        \n",
    "        data = self.data_manager.data\n",
    "        group_col = self.data_manager.group_col\n",
    "        metric_col = self.data_manager.metric_col\n",
    "        \n",
    "        sns.histplot(\n",
    "            data=data, x=metric_col, hue=group_col,\n",
    "            kde=kde, element=\"step\", common_norm=False,\n",
    "            alpha=0.6, bins=25, ax=ax\n",
    "        )\n",
    "        \n",
    "        if rug:\n",
    "            sns.rugplot(\n",
    "                data=data, x=metric_col, hue=group_col,\n",
    "                height=0.05, alpha=0.5, ax=ax\n",
    "            )\n",
    "        \n",
    "        # Adiciona médias verticais\n",
    "        for group, color in zip([self.data_manager.group_a, self.data_manager.group_b], sns.color_palette()[:2]):\n",
    "            group_mean = data[data[group_col] == group][metric_col].mean()\n",
    "            ax.axvline(x=group_mean, color=color, linestyle='--', \n",
    "                      label=f'Média {group}: {group_mean:.2f}')\n",
    "            \n",
    "        ax.set_xlabel(metric_col.capitalize())\n",
    "        ax.set_ylabel('Densidade')\n",
    "        ax.set_title(f'Distribuições de {metric_col.capitalize()} por Grupo')\n",
    "        ax.legend(title=group_col.capitalize())\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_boxplot(self, violin: bool = True, points: bool = True) -> plt.Figure:\n",
    "        \"\"\"Plota boxplots dos grupos A e B, opcionalmente com violino e pontos.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        data = self.data_manager.data\n",
    "        group_col = self.data_manager.group_col\n",
    "        metric_col = self.data_manager.metric_col\n",
    "        \n",
    "        if violin:\n",
    "            sns.violinplot(\n",
    "                data=data, x=group_col, y=metric_col,\n",
    "                inner=None, alpha=0.4, ax=ax\n",
    "            )\n",
    "            \n",
    "        sns.boxplot(\n",
    "            data=data, x=group_col, y=metric_col,\n",
    "            width=0.5, fliersize=0, ax=ax\n",
    "        )\n",
    "        \n",
    "        if points:\n",
    "            sns.stripplot(\n",
    "                data=data, x=group_col, y=metric_col,\n",
    "                size=4, alpha=0.3, jitter=0.3, ax=ax\n",
    "            )\n",
    "            \n",
    "        ax.set_xlabel(group_col.capitalize())\n",
    "        ax.set_ylabel(metric_col.capitalize())\n",
    "        ax.set_title(f'Comparação de {metric_col.capitalize()} entre Grupos')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def plot_confidence_interval(self, test_result: TTestResult) -> plt.Figure:\n",
    "        \"\"\"Plota o intervalo de confiança da diferença entre médias.\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        \n",
    "        # Dados para o gráfico\n",
    "        x = ['Diferença (A - B)']\n",
    "        y = [test_result.mean_diff]\n",
    "        ci = [[test_result.mean_diff - test_result.ci_low], [test_result.ci_high - test_result.mean_diff]]\n",
    "        \n",
    "        # Plot\n",
    "        ax.errorbar(x, y, yerr=ci, fmt='o', capsize=10, capthick=2, elinewidth=2,\n",
    "                  markersize=10, color='royalblue')\n",
    "        \n",
    "        # Linha horizontal em y=0\n",
    "        ax.axhline(y=0, linestyle='--', color='gray', alpha=0.7)\n",
    "        \n",
    "        # Região do intervalo de confiança\n",
    "        ax.fill_between([-0.25, 0.25], test_result.ci_low, test_result.ci_high, \n",
    "                       alpha=0.2, color='royalblue', transform=ax.get_xaxis_transform())\n",
    "        \n",
    "        # Formato do gráfico\n",
    "        ax.set_ylabel('Diferença entre Médias')\n",
    "        ax.set_title(f'Intervalo de Confiança (95%) da Diferença entre Médias\\n{test_result.test_type}')\n",
    "        \n",
    "        # Anotações para interpretação\n",
    "        if test_result.is_significant():\n",
    "            status_text = \"Estatisticamente Significativo (p < 0.05)\"\n",
    "            status_color = 'green'\n",
    "        else:\n",
    "            status_text = \"Não Significativo (p >= 0.05)\"\n",
    "            status_color = 'red'\n",
    "            \n",
    "        ax.annotate(\n",
    "            f\"Diferença: {test_result.mean_diff:.4f}\\n\" +\n",
    "            f\"IC 95%: [{test_result.ci_low:.4f}, {test_result.ci_high:.4f}]\\n\" +\n",
    "            f\"p-valor: {test_result.p_value:.4f}\\n\" +\n",
    "            f\"{status_text}\",\n",
    "            xy=(0, test_result.mean_diff),\n",
    "            xytext=(0.6, 0.5),\n",
    "            textcoords='axes fraction',\n",
    "            ha='center',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.5\", fc=\"white\", ec=status_color, alpha=0.8),\n",
    "            arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=0.2\", color=status_color)\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "        \n",
    "    def plot_qq(self) -> plt.Figure:\n",
    "        \"\"\"Plota gráficos Q-Q para verificar a normalidade dos dados.\"\"\"\n",
    "        group_a_data, group_b_data = self.data_manager.get_groups_data()\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "        \n",
    "        # Gráfico Q-Q para o grupo A\n",
    "        stats.probplot(group_a_data, dist=\"norm\", plot=axes[0])\n",
    "        axes[0].set_title(f'Gráfico Q-Q para Grupo {self.data_manager.group_a}')\n",
    "        \n",
    "        # Gráfico Q-Q para o grupo B\n",
    "        stats.probplot(group_b_data, dist=\"norm\", plot=axes[1])\n",
    "        axes[1].set_title(f'Gráfico Q-Q para Grupo {self.data_manager.group_b}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa248dd0",
   "metadata": {},
   "source": [
    "## Análise de Campanha A/B\n",
    "\n",
    "Vamos analisar uma campanha A/B usando dados sintéticos. Primeiro, criamos os dados com uma diferença conhecida entre os grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6b5aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando dados sintéticos para análise\n",
    "campaign_data = CampaignDataManager()\n",
    "campaign_data.generate_synthetic_data(\n",
    "    n_samples_a=200,\n",
    "    n_samples_b=200,\n",
    "    mean_a=50,    # Conversão média do grupo A\n",
    "    mean_b=55,    # Conversão média do grupo B (5% superior)\n",
    "    std_a=15,\n",
    "    std_b=15\n",
    ")\n",
    "\n",
    "# Exibir estatísticas descritivas\n",
    "campaign_data.get_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bbe75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando as distribuições\n",
    "visualizer = ResultVisualizer(campaign_data)\n",
    "visualizer.plot_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd27f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando boxplots e gráficos QQ\n",
    "visualizer.plot_boxplot()\n",
    "visualizer.plot_qq()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d43150",
   "metadata": {},
   "source": [
    "## Verificação de Pressupostos\n",
    "\n",
    "Antes de realizar o teste t, é importante verificar os pressupostos:\n",
    "\n",
    "1. Normalidade dos dados em cada grupo\n",
    "2. Homogeneidade das variâncias\n",
    "\n",
    "Se os pressupostos não forem atendidos, podemos precisar usar testes alternativos ou ajustar a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd117c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o analisador de testes t\n",
    "ttest_analyzer = TTestAnalyzer(campaign_data)\n",
    "\n",
    "# Verificar normalidade\n",
    "normality_results = ttest_analyzer.check_normality()\n",
    "print(\"Teste de Normalidade (Shapiro-Wilk):\")\n",
    "for group, result in normality_results.items():\n",
    "    print(f\"Grupo {group}: Estatística = {result['statistic']:.4f}, p-valor = {result['p_value']:.4f}\")\n",
    "    if result['p_value'] < 0.05:\n",
    "        print(f\"   ❌ Os dados do grupo {group} não parecem seguir uma distribuição normal.\")\n",
    "    else:\n",
    "        print(f\"   ✅ Os dados do grupo {group} parecem seguir uma distribuição normal.\")\n",
    "\n",
    "# Verificar homogeneidade das variâncias\n",
    "homogeneity_result = ttest_analyzer.check_homogeneity_of_variance()\n",
    "print(\"\\nTeste de Homogeneidade das Variâncias (Levene):\")\n",
    "print(f\"Estatística = {homogeneity_result['statistic']:.4f}, p-valor = {homogeneity_result['p_value']:.4f}\")\n",
    "if homogeneity_result['p_value'] < 0.05:\n",
    "    print(\"   ❌ As variâncias entre os grupos são significativamente diferentes.\")\n",
    "    print(\"   ⚠️ Recomenda-se usar o teste t de Welch (equal_var=False).\")\n",
    "else:\n",
    "    print(\"   ✅ As variâncias entre os grupos são aproximadamente iguais.\")\n",
    "    print(\"   ✓ Pode-se usar o teste t de Student padrão (equal_var=True).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a916eb1a",
   "metadata": {},
   "source": [
    "## Realizando o Teste t\n",
    "\n",
    "Com base na verificação de pressupostos, vamos realizar o teste t apropriado (Student ou Welch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca6023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar o teste t independente\n",
    "result = ttest_analyzer.run_independent_ttest()\n",
    "\n",
    "# Exibir resultado\n",
    "print(result.summary())\n",
    "\n",
    "# Visualizar o intervalo de confiança\n",
    "visualizer.plot_confidence_interval(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683b95b",
   "metadata": {},
   "source": [
    "## Análise de Poder Estatístico\n",
    "\n",
    "Vamos analisar o poder estatístico do teste realizado e determinar o tamanho amostral necessário para detectar diferentes tamanhos de efeito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciar o analisador de poder estatístico\n",
    "power_analyzer = PowerAnalyzer()\n",
    "\n",
    "# Obter o tamanho do efeito da análise\n",
    "effect_size = result.effect_size\n",
    "\n",
    "# Calcular o poder estatístico para o tamanho de amostra atual\n",
    "n1, n2 = len(campaign_data.get_group_data('A')), len(campaign_data.get_group_data('B'))\n",
    "power = power_analyzer.calculate_power(effect_size, n1, n2)\n",
    "\n",
    "print(f\"Tamanho do efeito (d de Cohen): {effect_size:.4f} ({power_analyzer.cohen_d_interpretation(effect_size)})\")\n",
    "print(f\"Poder estatístico do teste atual: {power:.4f} (com n1={n1}, n2={n2})\")\n",
    "\n",
    "# Calcular o tamanho de amostra necessário para um poder de 0.8\n",
    "sample_size_needed = power_analyzer.calculate_sample_size(effect_size)\n",
    "print(f\"Tamanho de amostra necessário para poder de 0.8: {sample_size_needed} por grupo\")\n",
    "\n",
    "# Plotar análise de poder para diferentes tamanhos de efeito\n",
    "effect_sizes = [0.2, 0.3, 0.5, 0.8]  # Pequeno, médio, grande\n",
    "ns = [10, 25, 50, 100, 200, 300, 500, 1000]\n",
    "\n",
    "power_analyzer.plot_power_analysis(effect_sizes, ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff2c8b",
   "metadata": {},
   "source": [
    "## Interpretação dos Resultados\n",
    "\n",
    "Nesta análise, avaliamos se existe uma diferença estatisticamente significativa entre os grupos A e B da campanha. Os resultados principais são:\n",
    "\n",
    "1. **Pressupostos**: \n",
    "   - Os testes de normalidade confirmam que os dados em ambos os grupos seguem aproximadamente uma distribuição normal.\n",
    "   - O teste de Levene indica que as variâncias são homogêneas entre os grupos.\n",
    "\n",
    "2. **Resultado do Teste t**:\n",
    "   - A diferença média entre os grupos foi de aproximadamente 5 pontos.\n",
    "   - O intervalo de confiança de 95% para a diferença é estatisticamente significativo (não inclui zero).\n",
    "   - O valor-p é menor que 0.05, indicando que há uma diferença estatisticamente significativa entre os grupos.\n",
    "\n",
    "3. **Tamanho do Efeito e Poder**:\n",
    "   - O tamanho do efeito (d de Cohen) é de aproximadamente 0.33, considerado um efeito \"pequeno\" a \"médio\".\n",
    "   - O poder estatístico atual é adequado, mas para efeitos menores, seria necessário um tamanho amostral maior.\n",
    "   - Para um poder de 0.8, o tamanho de amostra ideal por grupo foi calculado.\n",
    "\n",
    "4. **Implicações Práticas**:\n",
    "   - A versão B da campanha produziu resultados significativamente melhores que a versão A.\n",
    "   - A magnitude do efeito sugere uma melhoria prática importante que justifica a adoção da versão B.\n",
    "   - Os resultados são confiáveis dada a verificação de pressupostos e poder estatístico adequado.\n",
    "\n",
    "É importante ressaltar que a significância estatística não implica necessariamente relevância prática. A decisão de adotar a versão B deve considerar também fatores de custo, implementação e alinhamento estratégico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c7a8c7",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "Esta análise demonstrou como realizar e interpretar um teste t para avaliar campanhas A/B com rigor estatístico. Os elementos-chave incluíram:\n",
    "\n",
    "1. Verificação de pressupostos estatísticos (normalidade, homogeneidade das variâncias)\n",
    "2. Escolha do teste apropriado (Student ou Welch) com base nos pressupostos\n",
    "3. Interpretação dos resultados com intervalos de confiança\n",
    "4. Análise do tamanho do efeito e poder estatístico\n",
    "5. Visualizações informativas para comunicar os resultados\n",
    "\n",
    "Este framework pode ser aplicado a diversas situações onde é necessário comparar médias entre dois grupos, como testes A/B em marketing digital, experimentos científicos, ou estudos clínicos.\n",
    "\n",
    "**Limitações e Considerações:**\n",
    "\n",
    "- Para dados que violam severamente os pressupostos de normalidade, testes não-paramétricos como Mann-Whitney U podem ser mais apropriados.\n",
    "- Para análises mais complexas com múltiplas variáveis ou grupos, técnicas como ANOVA, regressão ou modelos mistos podem ser necessárias.\n",
    "- A randomização adequada e o controle de variáveis confundidoras são cruciais para a validade dos resultados em experimentos reais.\n",
    "\n",
    "**Referências Bibliográficas:**\n",
    "\n",
    "1. Cohen, J. (1988). Statistical power analysis for the behavioral sciences (2nd ed.). Lawrence Erlbaum Associates.\n",
    "2. Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science: A practical primer for t-tests and ANOVAs. Frontiers in Psychology, 4, 863.\n",
    "3. Welch, B. L. (1947). The generalization of 'Student's' problem when several different population variances are involved. Biometrika, 34(1/2), 28-35."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
